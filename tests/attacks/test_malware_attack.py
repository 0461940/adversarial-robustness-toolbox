# MIT License
#
# Copyright (C) The Adversarial Robustness Toolbox (ART) Authors 2020
#
# Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
# documentation files (the "Software"), to deal in the Software without restriction, including without limitation the
# rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit
# persons to whom the Software is furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in all copies or substantial portions of the
# Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
# WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
# TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.

import unittest
import numpy as np
import tensorflow as tf
import copy

from art.attacks.evasion.pe_malware_attack import MalwareGD


class TestMalwareAttack(unittest.TestCase):

    def test_generate(self):

        b, y, size_of_original_files = self.generate_synthetic_data()

        # setup classifier
        param_dic = {'maxlen': 2 ** 20,
                     'input_dim': 257,
                     'embedding_size': 8}
        model_weights = tf.keras.models.load_model('../../../train_softmax_version/normal_training/Models/model_0').get_weights()

        # make a copy of the original data.
        original_data = copy.copy(b)
        original_labels = copy.copy(y)

        # First check: with no pertubation the malware of sufficient size, and benign files, should be unperturbed
        attack = MalwareGD(model_weights=model_weights,
                           l0=0,
                           param_dic=param_dic)

        adv_x, y_adv = attack.generate(b, y, size_of_original_files)

        # We should only have 3 files as the following cannot be converted to valid adv samples:
        #   2nd datapoint (file to large to support any modificaitons)
        #   5th datapoint (benign file)

        assert len(adv_x) == 3

        j = 0
        for i, size in enumerate(size_of_original_files):
            if i in [0, 2, 3]:
                assert np.array_equal(adv_x[j], original_data[i])
                j += 1

        # Second check: Append Attack of size 1000.
        l0_budget = 1250
        attack.l0 = l0_budget
        adv_x, y_adv = attack.generate(b, y, size_of_original_files)
        # We should only have 2 files as the following cannot be converted to valid adv samples:
        #   2nd datapoint (file to large to support any modificaitons)
        #   4th datapoint (file to large to support append attacks)
        #   5th datapoint (benign file)

        assert len(adv_x) == 2
        j = 0
        for i, size in enumerate(size_of_original_files):
            if i in [0, 2]:
                assert np.array_equal(adv_x[j, :size], original_data[i, :size])
                assert not np.array_equal(adv_x[j, size:size+l0_budget], original_data[i, size:size+l0_budget])
                assert np.array_equal(adv_x[j, size+l0_budget:], original_data[i, size+l0_budget:])
                j += 1

        # Third check: Slack insertion attacks.
        batch_of_slack_starts, batch_of_slack_sizes = self.generate_synthetic_slack_regions(size=250)
        assert np.array_equal(b, original_data)
        adv_x, y_adv = attack.generate(b, y, size_of_original_files,
                                       batch_of_slack_sizes=batch_of_slack_sizes,
                                       batch_of_slack_starts=batch_of_slack_starts)

        # We should only have 2 files as the following cannot be converted to valid adv samples:
        #   2nd datapoint (file to large to support any modificaitons)
        #   4th datapoint (attack requires appending 250 bytes to end of file which this datapoint cannot support)
        #   5th datapoint (benign file)
        assert len(adv_x) == 2

        j = 0
        for i, size in enumerate(size_of_original_files):
            if i in [0, 2]:
                slack_starts = batch_of_slack_starts[i]
                slack_sizes = batch_of_slack_sizes[i]
                begning_pos = 0
                total_pertubation = 0
                for slack_start, slack_size in zip(slack_starts, slack_sizes):
                    assert np.array_equal(adv_x[j, begning_pos:slack_start],
                                          original_data[i, begning_pos:slack_start])

                    assert not np.array_equal(adv_x[j, begning_pos:begning_pos+slack_start+slack_size],
                                              original_data[i, begning_pos:begning_pos+slack_start+slack_size])
                    begning_pos = slack_start+slack_size
                    total_pertubation += slack_size

                # from the last slack region to end of file
                assert np.array_equal(adv_x[j, begning_pos:size],
                                      original_data[i, begning_pos:size])
                remaining_perturbation = l0_budget - total_pertubation
                assert remaining_perturbation == 250

                # append portion of the attack has been conducted
                assert not np.array_equal(adv_x[j, size:size+remaining_perturbation],
                                      original_data[i, size:size+remaining_perturbation])

                # from end of append to end of datapoint
                assert np.array_equal(adv_x[j, size+remaining_perturbation:],
                                      original_data[i, size+remaining_perturbation:])

                j += 1

        # Fourth check append large perturbation

        l0_budget = int(((2**20)*0.2))
        attack.l0 = l0_budget
        adv_x, y_adv = attack.generate(b, y, size_of_original_files)

        # We should only have one datapoint that can support an append pertubation of this size
        assert len(adv_x) == 1
        j=0
        for i, size in enumerate(size_of_original_files):
            if i ==0:
                assert np.array_equal(adv_x[j, :size], original_data[i, :size])
                assert not np.array_equal(adv_x[j, size:size + l0_budget], original_data[i, size:size + l0_budget])
                assert np.array_equal(adv_x[j, size + l0_budget:], original_data[i, size + l0_budget:])



    @staticmethod
    def generate_synthetic_data():
        # generate dummy data
        padding_char = 256
        maxlen = 2**20

        # batch of 5 datapoints
        b = np.ones((5, maxlen), dtype=np.uint16) * padding_char

        size_of_original_files = [int(maxlen*0.1),   # 1 sample significantly smaller than the maxlen
                                  int(maxlen*1.5),   # 1 sample larger then maxlen
                                  int(maxlen*0.95),  # 1 sample close to the maximum of the maxlen
                                  int(maxlen),       # 1 sample at the maxlen
                                  int(maxlen)]       # 1 sample at the maxlen, this will be assigned a benign label and
                                                     # should not be perturbed by the attack.

        # two class option, later change to binary when ART is generally updated.
        y = np.zeros((5, 2))
        y[0:4, 1] = 1  # assign the first 4 datapoints to be labeled as malware
        y[-1, 0] = 1  # assign the last datapoint to be benign

        # fill in with random numbers
        for i, size in enumerate(size_of_original_files):
            if size > maxlen:
                size = maxlen
            b[i, 0:size] = np.random.randint(low=0, high=256, size=(1, size))

        return b, y, size_of_original_files

    @staticmethod
    def generate_synthetic_slack_regions(size):
        """
        Generate 4 slack regions per sample, each of size 250.
        """

        batch_of_slack_starts = []
        batch_of_slack_sizes = []

        for _ in range(5):
            size_of_slack = []
            start_of_slack = []
            start = 0
            for _ in range(4):
                start += 1000
                start_of_slack.append(start)
                size_of_slack.append(size)
            batch_of_slack_starts.append(start_of_slack)
            batch_of_slack_sizes.append(size_of_slack)
        return batch_of_slack_starts, batch_of_slack_sizes


