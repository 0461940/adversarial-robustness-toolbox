# MIT License
#
# Copyright (C) The Adversarial Robustness Toolbox (ART) Authors 2020
#
# Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
# documentation files (the "Software"), to deal in the Software without restriction, including without limitation the
# rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit
# persons to whom the Software is furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in all copies or substantial portions of the
# Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
# WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
# TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.

import unittest
import numpy as np
import copy

from art.attacks.evasion.pe_malware_attack import MalwareGD


class TestMalwareAttack(unittest.TestCase):

    def test_generate(self):

        b, y, size_of_original_files = self.generate_synthetic_data()

        # setup classifier
        param_dic = {'maxlen': 2 ** 20,
                     'input_dim': 257,
                     'embedding_size': 8}
        model_weights = self.make_dummy_model()
        # make a copy of the original data.
        original_data = copy.copy(b)

        # First check: with no pertubation the malware of sufficient size, and benign files, should be unperturbed
        attack = MalwareGD(model_weights=model_weights,
                           l_0=0,
                           param_dic=param_dic)

        adv_x, y_adv = attack.generate(b, y, size_of_original_files)

        # We should only have 3 files as the following cannot be converted to valid adv samples:
        #   2nd datapoint (file to large to support any modificaitons)
        #   5th datapoint (benign file)

        assert len(adv_x) == 3

        j = 0
        for i, size in enumerate(size_of_original_files):
            if i in [0, 2, 3]:
                assert np.array_equal(adv_x[j], original_data[i])
                j += 1

        # Second check: Append Attack of size 1000.
        l0_budget = 1250
        attack.l_0 = l0_budget
        adv_x, y_adv = attack.generate(b, y, size_of_original_files)
        # We should only have 2 files as the following cannot be converted to valid adv samples:
        #   2nd datapoint (file to large to support any modificaitons)
        #   4th datapoint (file to large to support append attacks)
        #   5th datapoint (benign file)

        assert len(adv_x) == 2
        j = 0
        for i, size in enumerate(size_of_original_files):
            if i in [0, 2]:
                assert np.array_equal(adv_x[j, :size], original_data[i, :size])
                assert not np.array_equal(adv_x[j, size:size+l0_budget], original_data[i, size:size+l0_budget])
                assert np.array_equal(adv_x[j, size+l0_budget:], original_data[i, size+l0_budget:])
                j += 1

        # Third check: Slack insertion attacks.
        batch_of_section_starts, batch_of_section_sizes = self.generate_synthetic_slack_regions(size=250)
        assert np.array_equal(b, original_data)
        adv_x, y_adv = attack.generate(b, y, size_of_original_files,
                                       perturb_sizes=batch_of_section_sizes,
                                       perturb_starts=batch_of_section_starts)

        # We should only have 2 files as the following cannot be converted to valid adv samples:
        #   2nd datapoint (file to large to support any modificaitons)
        #   4th datapoint (attack requires appending 250 bytes to end of file which this datapoint cannot support)
        #   5th datapoint (benign file)
        assert len(adv_x) == 2

        j = 0
        for i, size in enumerate(size_of_original_files):
            if i in [0, 2]:
                slack_starts = batch_of_section_starts[i]
                slack_sizes = batch_of_section_sizes[i]
                begning_pos = 0
                total_pertubation = 0
                for slack_start, slack_size in zip(slack_starts, slack_sizes):
                    assert np.array_equal(adv_x[j, begning_pos:slack_start],
                                          original_data[i, begning_pos:slack_start])

                    assert not np.array_equal(adv_x[j, begning_pos:begning_pos+slack_start+slack_size],
                                              original_data[i, begning_pos:begning_pos+slack_start+slack_size])
                    begning_pos = slack_start+slack_size
                    total_pertubation += slack_size

                # from the last slack region to end of file
                assert np.array_equal(adv_x[j, begning_pos:size],
                                      original_data[i, begning_pos:size])
                remaining_perturbation = l0_budget - total_pertubation
                assert remaining_perturbation == 250

                # append portion of the attack has been conducted
                assert not np.array_equal(adv_x[j, size:size+remaining_perturbation],
                                      original_data[i, size:size+remaining_perturbation])

                # from end of append to end of datapoint
                assert np.array_equal(adv_x[j, size+remaining_perturbation:],
                                      original_data[i, size+remaining_perturbation:])

                j += 1

        # Fourth check append large perturbation

        l0_budget = int(((2**20)*0.2))
        attack.l_0 = l0_budget
        adv_x, y_adv = attack.generate(b, y, size_of_original_files)

        # We should only have one datapoint that can support an append perturbation of this size
        assert len(adv_x) == 1
        j = 0
        for i, size in enumerate(size_of_original_files):
            if i == 0:
                assert np.array_equal(adv_x[j, :size], original_data[i, :size])
                assert not np.array_equal(adv_x[j, size:size + l0_budget], original_data[i, size:size + l0_budget])
                assert np.array_equal(adv_x[j, size + l0_budget:], original_data[i, size + l0_budget:])

        # 5th check: DOS header attack

        l0_budget = 290
        attack.l_0 = l0_budget
        assert np.array_equal(b, original_data)

        dos_starts, dos_sizes = attack.get_dos_locations(b)
        adv_x, y_adv = attack.generate(b, y, size_of_original_files,
                                       perturb_sizes=dos_sizes,
                                       perturb_starts=dos_starts)

        # should have 3 files. Samples which are excluded are:
        #   2nd datapoint (file to large to support any modifications)
        #   5th datapoint (benign file)

        j = 0
        for i in range(len(adv_x)):
            if i in [0, 2, 3]:
                print('sample ', i)
                assert np.array_equal(adv_x[j, 0:2], [77, 90])

                # we should have 58 bytes that were perturbed between the magic number and the pointer
                assert not np.array_equal(adv_x[j, 2:int(0x3C)], b[i, 2:int(0x3C)])

                # dummy pointer should be unchanged
                assert np.array_equal(adv_x[j, int(0x3C):int(0x3C)+4], [44, 1, 0, 0])

                # the remaining perturbation 290 - 58 = 232 is in the rest of the DOS header
                assert not np.array_equal(adv_x[j, int(0x3C)+4:int(0x3C)+4+232], b[i, int(0x3C)+4:int(0x3C)+4+232])

                # rest of the file is unchanged
                assert np.array_equal(adv_x[j, int(0x3C)+4+232:],  b[i, int(0x3C)+4+232:])
                j += 1

        # 6th check: Do not automatically append extra perturbation
        l0_budget = 1250
        attack.l_0 = l0_budget
        assert np.array_equal(b, original_data)

        adv_x, y_adv = attack.generate(b, y, size_of_original_files,
                                       automatically_append=False,
                                       perturb_sizes=batch_of_section_sizes,
                                       perturb_starts=batch_of_section_starts)

        # should have 3 samples.
        # 2nd datapoint cannot support any modification
        # 5th is a benign sample
        assert len(adv_x) == 3
        j = 0
        for i in range(len(adv_x)):
            if i in [0, 2, 3]:
                slack_starts = batch_of_section_starts[i]
                slack_sizes = batch_of_section_sizes[i]
                begning_pos = 0
                total_pertubation = 0
                for slack_start, slack_size in zip(slack_starts, slack_sizes):
                    assert np.array_equal(adv_x[j, begning_pos:slack_start],
                                          original_data[i, begning_pos:slack_start])

                    assert not np.array_equal(adv_x[j, begning_pos:begning_pos + slack_start + slack_size],
                                              original_data[i, begning_pos:begning_pos + slack_start + slack_size])
                    begning_pos = slack_start + slack_size
                    total_pertubation += slack_size
                    print('begning_pos', begning_pos)
                # from end of final inserted perturbation to EOF.
                assert np.array_equal(adv_x[j, begning_pos:], original_data[i, begning_pos:])
                j += 1

    @staticmethod
    def generate_synthetic_data():
        # generate dummy data
        padding_char = 256
        maxlen = 2**20

        # batch of 5 datapoints
        b = np.ones((5, maxlen), dtype=np.uint16) * padding_char

        size_of_original_files = [int(maxlen*0.1),   # 1 sample significantly smaller than the maxlen
                                  int(maxlen*1.5),   # 1 sample larger then maxlen
                                  int(maxlen*0.95),  # 1 sample close to the maximum of the maxlen
                                  int(maxlen),       # 1 sample at the maxlen
                                  int(maxlen)]       # 1 sample at the maxlen, this will be assigned a benign label and
                                                     # should not be perturbed by the attack.

        # two class option, later change to binary when ART is generally updated.
        y = np.zeros((5, 1))
        y[0:4] = 1  # assign the first 4 datapoints to be labeled as malware

        # fill in with random numbers
        for i, size in enumerate(size_of_original_files):
            if size > maxlen:
                size = maxlen
            b[i, 0:size] = np.random.randint(low=0, high=256, size=(1, size))

        # set the DOS header values:
        b[:, 0:2] = [77, 90]
        b[:, int(0x3C):int(0x40)] = 0  # zero the pointer location
        b[:, int(0x3C)] = 44  # put in a dummy pointer
        b[:, int(0x3C) + 1] = 1  # put in a dummy pointer
        return b, y, size_of_original_files

    @staticmethod
    def generate_synthetic_slack_regions(size):
        """
        Generate 4 slack regions per sample, each of size 250.
        """

        batch_of_slack_starts = []
        batch_of_slack_sizes = []

        for _ in range(5):
            size_of_slack = []
            start_of_slack = []
            start = 0
            for _ in range(4):
                start += 1000
                start_of_slack.append(start)
                size_of_slack.append(size)
            batch_of_slack_starts.append(start_of_slack)
            batch_of_slack_sizes.append(size_of_slack)
        return batch_of_slack_starts, batch_of_slack_sizes

    @staticmethod
    def make_dummy_model():

        model_weight_shapes = [(257, 8),
                               (500, 8, 128),
                               (128,),
                               (500, 8, 128),
                               (128,),
                               (128, 128),
                               (128,),
                               (128, 1),
                               (1,)]
        model_weights = []

        for ws in model_weight_shapes:
            model_weights.append(np.random.normal(loc=0, scale=1.0, size=ws))

        return model_weights
