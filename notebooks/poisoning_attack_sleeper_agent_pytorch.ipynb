{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "167d8f6c",
   "metadata": {},
   "source": [
    "# This notebook implements sleeper agent attack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fc35bd",
   "metadata": {},
   "source": [
    "In this notebook, we will learn how to use ART to run a Hidden Trigger Backdoor Attack Sleeper Agent poisoning attack on a neural network trained with Pytorch. We will be training our data on a subset of the CIFAR-10 dataset. The methods described are derived from [this paper](https://arxiv.org/pdf/2106.08970.pdf) by Hossein Souri, et. al. 2021."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "501c126e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from tqdm import trange\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import pdb\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "from skimage.transform import resize\n",
    "import random\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "from art.utils import load_cifar10\n",
    "from torchvision.models.resnet import BasicBlock, Bottleneck\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torchvision\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9de724d",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "module_path = os.path.abspath(os.path.join('.'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fd61d1",
   "metadata": {},
   "source": [
    "# Substitute Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a4f0cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test), min_, max_ = load_cifar10()\n",
    "x_train = np.transpose(x_train, (0, 3, 1, 2)).astype(np.float32)\n",
    "x_test = np.transpose(x_test, (0, 3, 1, 2)).astype(np.float32)\n",
    "mean = np.mean(x_train,axis=(0,1,2,3))\n",
    "std = np.std(x_train,axis=(0,1,2,3))\n",
    "\n",
    "patch_size = 8\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "img = Image.open('trigger_10.png')\n",
    "numpydata = asarray(img)\n",
    "patch = resize(numpydata, (patch_size,patch_size,3))\n",
    "patch = np.transpose(patch,(2,0,1))\n",
    "x_train_orig = np.copy(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69e3ffe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_classes = 10\n",
    "# loss_fn = nn.CrossEntropyLoss()\n",
    "# model = torchvision.models.ResNet(torchvision.models.resnet.BasicBlock, [2, 2, 2, 2], num_classes=num_classes)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4, nesterov=True)\n",
    "# model_art = PyTorchClassifier(model,input_shape=x_train.shape[1:], loss=loss_fn, optimizer=optimizer, nb_classes=10, clip_values=(min_, max_), preprocessing=(mean,std))\n",
    "# model_art.fit(x_train, y_train, batch_size=128, nb_epochs=80,verbose=0)\n",
    "# predictions = model_art.predict(x_test)\n",
    "# accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
    "# print(\"Accuracy on benign test examples: {}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38d0e8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on benign test examples: 73.95%\n"
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "model = torch.load('model.pt')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4, nesterov=True)\n",
    "model_art = PyTorchClassifier(model,input_shape=x_train.shape[1:], loss=loss_fn, optimizer=optimizer, nb_classes=10, clip_values=(min_, max_), preprocessing=(mean,std))\n",
    "predictions = model_art.predict(x_test)\n",
    "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
    "print(\"Accuracy on benign test examples: {}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d973a78c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "art.estimators.classification.pytorch.PyTorchClassifier(model=ModelWrapper(\n",
       "  (_model): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       "), loss=CrossEntropyLoss(), optimizer=SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    lr: 0.1\n",
       "    momentum: 0.9\n",
       "    nesterov: True\n",
       "    weight_decay: 0.0005\n",
       "), input_shape=(3, 32, 32), nb_classes=10, channels_first=True, clip_values=array([0., 1.], dtype=float32), preprocessing_defences=None, postprocessing_defences=None, preprocessing=StandardisationMeanStdPyTorch(mean=0.4733648896217346, std=0.25156906247138977, apply_fit=True, apply_predict=True, device=cuda:0))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_art"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1ca858",
   "metadata": {},
   "source": [
    "# Define Source and Target Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "535c3171",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_source = 0\n",
    "class_target = 1\n",
    "K = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8898bf97",
   "metadata": {},
   "source": [
    "# Select Triggers from Source Class and helper functions for calculating Success Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ffa74a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.utils import to_categorical\n",
    "from art.attacks.poisoning.sleeper_agent_attack import SleeperAgentAttack\n",
    "\n",
    "def select_trigger_train(x_train,y_train,K,class_source,class_target):\n",
    "    x_train_ = np.copy(x_train)\n",
    "    index_source = np.where(y_train.argmax(axis=1)==class_source)[0][0:K]\n",
    "    index_target = np.where(y_train.argmax(axis=1)==class_target)[0]\n",
    "    x_trigger = x_train_[index_source]\n",
    "    y_trigger  = to_categorical([class_target], nb_classes=10)\n",
    "    y_trigger = np.tile(y_trigger,(len(index_source),1))\n",
    "    return x_trigger,y_trigger,index_target\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac33a35",
   "metadata": {},
   "source": [
    "# Generate Poison Images through attack "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb2f48d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2ecf44c65d541d5882a44697c646fbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_trigger,y_trigger,index_target = select_trigger_train(x_train,y_train,K,class_source,class_target)\n",
    "attack = SleeperAgentAttack(model_art,\n",
    "                                percent_poison=0.20,\n",
    "                                max_trials=1,\n",
    "                                max_epochs=250,\n",
    "                                learning_rate_schedule=(np.array([1e-1, 1e-2, 1e-3, 1e-4, 1e-5]), [250, 350, 400, 430, 460]),\n",
    "                                epsilon=16,\n",
    "                                batch_size=500,\n",
    "                                verbose=1,\n",
    "                                indices_target=index_target,\n",
    "                                patching_strategy=\"random\",\n",
    "                                selection_strategy=\"max-norm\",\n",
    "                                patch=patch,\n",
    "                                retraining_factor = 4,\n",
    "                                model_retrain = True,\n",
    "                                model_retraining_epoch = 80,\n",
    "                                class_source = class_source,\n",
    "                                class_target = class_target,\n",
    "                                device_name = str(device)       \n",
    "                           )\n",
    "x_poison, y_poison = attack.poison(x_trigger,y_trigger,x_train,y_train,x_test,y_test) \n",
    "indices_poison = attack.get_poison_indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8628d43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_poison.sort()\n",
    "print(len(indices_poison))\n",
    "indices_poison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90d3224",
   "metadata": {},
   "source": [
    "# Train Victim Model with poisoned images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddb074d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "model = torchvision.models.ResNet(torchvision.models.resnet.BasicBlock, [2, 2, 2, 2], num_classes=num_classes)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4, nesterov=True)\n",
    "model_poisoned = PyTorchClassifier(model,input_shape=x_train.shape[1:], loss=loss_fn, \n",
    "                                   optimizer=optimizer, nb_classes=10, clip_values=(min_, max_), \n",
    "                                   preprocessing=(mean,std))\n",
    "model_poisoned.fit(x_poison, y_poison, batch_size=128, nb_epochs=80,verbose=0)\n",
    "predictions = model_poisoned.predict(x_test)\n",
    "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
    "print(\"Accuracy on benign test examples: {}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7b803c",
   "metadata": {},
   "source": [
    "# Visualize Trigger, Original and Poisoned Images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e51496",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(np.transpose(x_trigger[0],(1,2,0)))\n",
    "plt.title('Trigger image')\n",
    "plt.show()\n",
    "\n",
    "index_poisoned_example = np.where([np.any(p!=o) for (p,o) in zip(x_poison,x_train)])[0]\n",
    "plt.imshow(np.transpose(x_train_orig[index_target[indices_poison][0]],(1,2,0)))\n",
    "plt.title('Original image')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(np.transpose(x_poison[index_target[indices_poison][0]],(1,2,0)))\n",
    "plt.title('Poisoned image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6515b3be",
   "metadata": {},
   "source": [
    "# Calculate Success Rate on x_train and x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f5d3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_trigger_patch(x_set,patch_type=\"fixed\"):\n",
    "    print(x_set.shape)\n",
    "    img = Image.open('trigger_10.png')\n",
    "    numpydata = asarray(img)\n",
    "    print(\"shape of numpydata\",numpydata.shape)\n",
    "    patch = resize(numpydata, (patch_size,patch_size,3))\n",
    "    patch = np.transpose(patch,(2,0,1))\n",
    "    print(\"shape of patch\",patch.shape)\n",
    "    if patch_type == \"fixed\":\n",
    "        x_set[:,:,-patch_size:,-patch_size:] = patch\n",
    "    else:\n",
    "        for x in x_set:\n",
    "            x_cord = random.randrange(0,x.shape[1] - patch.shape[1] + 1)\n",
    "            y_cord = random.randrange(0,x.shape[2] - patch.shape[2] + 1)\n",
    "            x[:,x_cord:x_cord+patch_size,y_cord:y_cord+patch_size]=patch\n",
    "\n",
    "    return x_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0101de38",
   "metadata": {},
   "source": [
    "# Calculate on train images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b65520",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_source_train = np.where(y_train.argmax(axis=1)==class_source)[0]\n",
    "x_train_trigger = x_train_orig[index_source_train]\n",
    "x_train_trigger = add_trigger_patch(x_train_trigger,\"random\")\n",
    "result_poisoned_train = model_poisoned.predict(x_train_trigger)\n",
    "print(result_poisoned_train[0])\n",
    "print(len(result_poisoned_train))\n",
    "\n",
    "success_train = (np.argmax(result_poisoned_train,axis=1)==1).sum()/result_poisoned_train.shape[0]\n",
    "print(\"Train Success Rate\",success_train)\n",
    "plt.imshow(np.transpose(x_train_trigger[1],(1,2,0)))\n",
    "plt.title('Trigger image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955b4e7b",
   "metadata": {},
   "source": [
    "# Calculate Success Rate on Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f725cdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_source_test = np.where(y_test.argmax(axis=1)==class_source)[0]\n",
    "x_test_trigger = x_test[index_source_test]\n",
    "x_test_trigger = add_trigger_patch(x_test_trigger,\"random\")\n",
    "result_poisoned_test = model_poisoned.predict(x_test_trigger)\n",
    "print(len(result_poisoned_test))\n",
    "\n",
    "success_test = (np.argmax(result_poisoned_test,axis=1)==1).sum()/result_poisoned_test.shape[0]\n",
    "print(\"Test Success Rate:\",success_test)\n",
    "\n",
    "plt.imshow(np.transpose(x_test_trigger[0],(1,2,0)))\n",
    "plt.title('Trigger image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddfcbfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e59d228",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d11bc53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "4ac3521ab0019a06e3dcc09888d33dc489f9be1674edd39862beb2263a1f08c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
