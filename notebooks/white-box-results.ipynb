{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "from os.path import join\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcdefaults() \n",
    "\n",
    "INPUT_PATH = \"../results/classifiers/mnist/\"\n",
    "CLASSIFIERS = [\"resnet/relu\", \"resnet/brelu\", \"cnn/relu\", \"cnn/brelu\"]\n",
    "               \n",
    "accuracies = {}\n",
    "for c in CLASSIFIERS:\n",
    "    with open(join(INPUT_PATH, c, \"accuracies.json\"), \"r\") as json_file:\n",
    "        accuracies[c] = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on white-box attacks with fgsm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f66aa5c5198>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Accuracy on white-box attacks with fgsm\")\n",
    "PATH = \"/dccstor/dlw/data/adversarial_learning/adversarial/mnist/\"\n",
    "\n",
    "train, test = {}, {}\n",
    "eps_values = [e/10 for e in range(1, 11)]\n",
    "\n",
    "for c in CLASSIFIERS:\n",
    "    train[c] = [accuracies[c][\"train_accuracy\"]]\n",
    "    test[c] = [accuracies[c][\"test_accuracy\"]]\n",
    "\n",
    "    for eps in eps_values:\n",
    "        train[c].append(accuracies[c][join(PATH, c, \"fgsm\", \"eps%.2f_train.npy\" % eps)])\n",
    "        test[c].append(accuracies[c][join(PATH, c, \"fgsm\", \"eps%.2f_test.npy\" % eps)])\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "plt.title(\"Train Accuracies\")\n",
    "\n",
    "for c in CLASSIFIERS:\n",
    "    plt.plot([0.] + eps_values, train[c], label=c)\n",
    "\n",
    "ax.set_xlim([0, 1])\n",
    "ax.set_ylim([0, 100])\n",
    "plt.legend()\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "plt.title(\"Test Accuracies\")\n",
    "\n",
    "for c in CLASSIFIERS:\n",
    "    plt.plot([0.] + eps_values, test[c], label=c)\n",
    "    \n",
    "ax.set_xlim([0, 1])\n",
    "ax.set_ylim([0, 100])\n",
    "    \n",
    "plt.subplots_adjust(bottom=0.1, right=2, top=0.9)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN seems to work better than a ResNet. \n",
    "- Is it due to the choice of ResNet? Maybe, as the accuracies on the true samples are slightly worse than those of a CNN\n",
    "\n",
    "CNN with Brelu activations is considerably better than a CNN with Relu activations on small perturbations.\n",
    "- Is it because we reduce the variance? Maybe, we need to try on CIFAR10 to check if the accuracy on true examples doesn't change.\n",
    "\n",
    "All in all, it seems that the linear hypothesis + accumulation of errors stand (and not the vanishing units), because \n",
    "1. by bounding the activation outputs we reduce the impact of the attack (brelu))\n",
    "2. by keeping the residual from the previous layers the accuracy doesn't improve (ResNet)\n",
    "\n",
    "Check on black-box attacks and on other datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on white-box attacks with deepfool\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f66aa4d3fd0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Accuracy on white-box attacks with deepfool\")\n",
    "\n",
    "train, test = {}, {}\n",
    "\n",
    "for c in CLASSIFIERS:\n",
    "    train[c] = accuracies[c][join(PATH, c, \"deepfool\", \"train.npy\")]\n",
    "    test[c] = accuracies[c][join(PATH, c, \"deepfool\", \"test.npy\")]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "plt.title(\"Train Accuracies\")\n",
    "\n",
    "for i,c in enumerate(CLASSIFIERS):\n",
    "    ax.bar(i, train[c], 1, label=c)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "plt.title(\"Test Accuracies\")\n",
    "\n",
    "for i,c in enumerate(CLASSIFIERS):\n",
    "    ax.bar(i, test[c], 1, label=c)\n",
    "    \n",
    "plt.subplots_adjust(bottom=0.1, right=2, top=0.9)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on white-box attacks with universal-deepfool\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f66aa3e2ac8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Accuracy on white-box attacks with universal-deepfool\")\n",
    "\n",
    "train, test = {}, {}\n",
    "\n",
    "for c in CLASSIFIERS:\n",
    "    train[c] = accuracies[c][join(PATH, c, \"universal\", \"train.npy\")]\n",
    "    test[c] = accuracies[c][join(PATH, c, \"universal\", \"test.npy\")]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "plt.title(\"Train Accuracies\")\n",
    "\n",
    "for i,c in enumerate(CLASSIFIERS):\n",
    "    ax.bar(i, train[c], 1, label=c)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "plt.title(\"Test Accuracies\")\n",
    "\n",
    "for i,c in enumerate(CLASSIFIERS):\n",
    "    ax.bar(i, test[c], 1, label=c)\n",
    "    \n",
    "plt.subplots_adjust(bottom=0.1, right=2, top=0.9)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "ResNet seems to work better, BUT this is just the accuracies with an umbounded perturbation. Probably, it needs smaller perturbations to be fooled.\n",
    "\n",
    "Need to show also the empirical robustness."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
