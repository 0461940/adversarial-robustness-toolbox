{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from os.path import abspath\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset and Model\n",
    "We will load the CIFAR10 dataset and a pre-trained alexnet model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.utils import load_dataset\n",
    "import numpy as np\n",
    "(x_train, y_train), (x_test, y_test), min_, max_ = load_dataset('cifar10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers, models, losses\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "# Source here: https://github.com/keras-team/keras/blob/master/examples/cifar10_cnn.py\n",
    "model.add(layers.Conv2D(32, (3, 3), padding=\"same\", activation='relu', input_shape=x_train.shape[1:]))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), padding=\"same\", activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "def train_step(model, images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images, training=True)\n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "loss_object = losses.CategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.estimators.classification import TensorFlowV2Classifier\n",
    "\n",
    "classifier = TensorFlowV2Classifier(\n",
    "    model=model,\n",
    "    loss_object=loss_object,\n",
    "    train_step=train_step,\n",
    "    nb_classes=10,\n",
    "    input_shape=(32, 32, 3),\n",
    "    clip_values=(min_, max_),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classifier.fit(x_train, y_train, nb_epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on benign test examples: 76.77000000000001%\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(x_test)\n",
    "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
    "print(\"Accuracy on benign test examples: {}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-07 13:54:14.511557: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf_model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('tf_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the Poison\n",
    "We now will generate the poison using the hidden trigger backdoor attack. First, we define the target and source classes as well as the backdoor trigger. The target class will be the class we want to insert poisoned data into. The source class will be the class we will add a trigger to in order to cause misclassification into the target.\n",
    "\n",
    "The backdoor trigger will be a small image patch inserted into the source class images. At test time, we should be able to use this trigger to cause the classifier to misclassify source class images with the trigger added as the target class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.attacks.poisoning.backdoor_attack import PoisoningAttackBackdoor\n",
    "target = np.array([0,0,0,0,1,0,0,0,0,0])\n",
    "source = np.array([0,0,0,1,0,0,0,0,0,0])\n",
    "\n",
    "# Backdoor Trigger Parameters\n",
    "patch_size = 8\n",
    "x_shift = 32 - patch_size - 5\n",
    "y_shift = 32 - patch_size - 5\n",
    "\n",
    "# Define the backdoor poisoning object. Calling backdoor.poison(x) will insert the trigger into x.\n",
    "from art.attacks.poisoning import perturbations\n",
    "def mod(x):\n",
    "    original_dtype = x.dtype\n",
    "    x = perturbations.insert_image(x, backdoor_path=\"../utils/data/backdoors/htbd.png\",\n",
    "                                   channels_first=False, random=False, x_shift=x_shift, y_shift=y_shift,\n",
    "                                   size=(patch_size,patch_size), mode='RGB', blend=1)\n",
    "    return x.astype(original_dtype)\n",
    "backdoor = PoisoningAttackBackdoor(mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we run the attack. `eps` controls how much the target images can be perturbed with respect to an l-infinity distance. `feature_layer` dicates with layer's output will be used to define the attack's loss. It can either be the name of the layer or the layer index according to the ART estimator. `poison_percent` controls how many poisoned samples will be generated based on the size of the input data.\n",
    "\n",
    "The attack will return poisoned inputs of the target class and the indicies in the data that those poisoned inputs should replace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "import six\n",
    "layer = 9\n",
    "i_layer = None\n",
    "if classifier.layer_names is None:  # pragma: no cover\n",
    "    raise ValueError(\"No layer names identified.\")\n",
    "\n",
    "if isinstance(layer, six.string_types):\n",
    "    if layer not in classifier.layer_names:  # pragma: no cover\n",
    "        raise ValueError(\"Layer name %s is not part of the graph.\" % layer)\n",
    "    for i_name, name in enumerate(classifier.layer_names):\n",
    "        if name == layer:\n",
    "            i_layer = i_name\n",
    "            break\n",
    "elif isinstance(layer, int):\n",
    "    if layer < -len(classifier.layer_names) or layer >= len(classifier.layer_names):  # pragma: no cover\n",
    "        raise ValueError(\n",
    "            \"Layer index %d is outside of range (-%d to %d).\"\n",
    "            % (layer, len(classifier.layer_names), len(classifier.layer_names) - 1)\n",
    "        )\n",
    "    i_layer = layer\n",
    "else:  # pragma: no cover\n",
    "    raise TypeError(\"Layer must be of type `str` or `int`.\")\n",
    "    \n",
    "print(layer)\n",
    "\n",
    "activation_model = tf.keras.Model(classifier._model.layers[0].input, classifier._model.layers[i_layer].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7e7c5e6df5d41d0bcb444f3647f324e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Hidden Trigger:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'TensorFlowV2Classifier' object has no attribute '_input'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_29678/698457491.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpoison_attack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHiddenTriggerBackdoor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_layer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackdoor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackdoor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay_coeff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoison_percent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.015\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpoison_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoison_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoison_attack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoison\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of poison samples generated:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoison_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ML/lib/python3.9/site-packages/art/attacks/poisoning/hidden_trigger_backdoor/hidden_trigger_backdoor.py\u001b[0m in \u001b[0;36mpoison\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \"\"\"\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoison\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ML/lib/python3.9/site-packages/art/attacks/poisoning/hidden_trigger_backdoor/hidden_trigger_backdoor_keras.py\u001b[0m in \u001b[0;36mpoison\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m                     \u001b[0mattack_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat1_var\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m                     \u001b[0mattack_grad_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattack_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_custom_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss_function'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mattack_grad_f\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TensorFlowV2Classifier' object has no attribute '_input'"
     ]
    }
   ],
   "source": [
    "from art.attacks.poisoning import HiddenTriggerBackdoor\n",
    "#%run Hidden_Trigger_keras.ipynb\n",
    "poison_attack = HiddenTriggerBackdoor(classifier, eps=16/255, target=target, source=source, feature_layer=9, backdoor=backdoor, learning_rate=0.01, decay_coeff = .1, decay_iter = 1000, max_iter=3000, batch_size=25, poison_percent=.015)\n",
    "\n",
    "poison_data, poison_indices = poison_attack.poison(x_train, y_train)\n",
    "print(\"Number of poison samples generated:\", len(poison_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune the Model\n",
    "Now, we must finetune the model using the poisoned data and a small number of clean training inputs.  Here, we randomly select an equal number of training inputs from each of the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create finetuning dataset\n",
    "dataset_size = 2500\n",
    "num_classes = 10\n",
    "num_per_class = dataset_size/num_classes\n",
    "\n",
    "poison_dataset_inds = []\n",
    "\n",
    "for i in range(num_classes):\n",
    "    class_inds = np.where(np.argmax(y_train,axis=1) == i)[0]\n",
    "    num_select = int(num_per_class)\n",
    "    if np.argmax(target) == i:\n",
    "        num_select = int(num_select - min(num_per_class,len(poison_data)))\n",
    "        poison_dataset_inds.append(poison_indices)\n",
    "        \n",
    "    if num_select != 0:\n",
    "        poison_dataset_inds.append(np.random.choice(class_inds, num_select, replace=False))\n",
    "    \n",
    "poison_dataset_inds = np.concatenate(poison_dataset_inds)\n",
    "\n",
    "poison_x = np.copy(x_train)\n",
    "poison_x[poison_indices] = poison_data\n",
    "poison_x = poison_x[poison_dataset_inds]\n",
    "\n",
    "poison_y = np.copy(y_train)[poison_dataset_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('keras_model')\n",
    "\n",
    "model.trainable = False\n",
    "model.compile(loss=losses.CategoricalCrossentropy(from_logits=True), optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KerasClassifier(clip_values=(min_, max_), model=model)\n",
    "predictions = classifier.predict(x_test)\n",
    "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
    "print(\"Accuracy on benign test examples: {}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "finetune_model = tf.keras.layers.Dense(10)(model.layers[-2].output)\n",
    "finetune_model = tf.keras.Model(inputs=model.inputs, outputs=finetune_model)\n",
    "finetune_model.summary()\n",
    "\n",
    "lr = 0.5\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "finetune_model.compile(loss=losses.CategoricalCrossentropy(from_logits=True), optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "finetune_classifier = KerasClassifier(clip_values=(min_, max_), model=finetune_model, use_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_test_inds = np.where(np.all(y_test == source, axis=1))[0]\n",
    "\n",
    "test_poisoned_samples, test_poisoned_labels  = backdoor.poison(x_test[trigger_test_inds], y_test[trigger_test_inds])\n",
    "\n",
    "\n",
    "for i in range(4):\n",
    "    predictions = finetune_classifier.predict(x_test)\n",
    "    accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
    "    print(\"Accuracy on benign test examples: {}%\".format(accuracy * 100))\n",
    "    \n",
    "    predictions = finetune_classifier.predict(x_test[trigger_test_inds])\n",
    "    b_accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test[trigger_test_inds], axis=1)) / len(trigger_test_inds)\n",
    "    print(\"Accuracy on benign trigger test examples: {}%\".format(b_accuracy * 100))\n",
    "    \n",
    "    predictions = finetune_classifier.predict(test_poisoned_samples)\n",
    "    p_accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(test_poisoned_labels,axis=1)) / len(test_poisoned_labels)\n",
    "    print(\"Accuracy on poison trigger test examples: {}%\".format(p_accuracy * 100))\n",
    "    p_success = np.sum(np.argmax(predictions, axis=1) == np.argmax(target)) / len(test_poisoned_labels)\n",
    "    print(\"Success on poison trigger test examples: {}%\".format(p_success * 100))\n",
    "    print()\n",
    "    print(\"Training Epoch\", i)\n",
    "    if i != 0:\n",
    "        lr *= 0.1\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "        #optimizer = tf.keras.optimizers.SGD(learning_rate=lr, momentum=0.9)\n",
    "        finetune_model.compile(loss=losses.CategoricalCrossentropy(from_logits=True), optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    finetune_classifier = KerasClassifier(clip_values=(min_, max_), model=finetune_model, use_logits=True)\n",
    "\n",
    "    finetune_classifier.fit(poison_x, poison_y, nb_epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final Performance\")\n",
    "predictions = finetune_classifier.predict(x_test)\n",
    "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
    "print(\"Accuracy on benign test examples: {}%\".format(accuracy * 100))\n",
    "\n",
    "predictions = finetune_classifier.predict(x_test[trigger_test_inds])\n",
    "b_accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test[trigger_test_inds], axis=1)) / len(trigger_test_inds)\n",
    "print(\"Accuracy on benign trigger test examples: {}%\".format(b_accuracy * 100))\n",
    "\n",
    "predictions = finetune_classifier.predict(test_poisoned_samples)\n",
    "p_accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(test_poisoned_labels,axis=1)) / len(test_poisoned_labels)\n",
    "print(\"Accuracy on poison trigger test examples: {}%\".format(p_accuracy * 100))\n",
    "p_success = np.sum(np.argmax(predictions, axis=1) == np.argmax(target)) / len(test_poisoned_labels)\n",
    "print(\"Success on poison trigger test examples: {}%\".format(p_success * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
