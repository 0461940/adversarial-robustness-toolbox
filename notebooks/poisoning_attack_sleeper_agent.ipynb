{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "167d8f6c",
   "metadata": {},
   "source": [
    "# This notebook implements sleeper agent attack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fc35bd",
   "metadata": {},
   "source": [
    "In this notebook, we will learn how to use ART to run a Hidden Trigger Backdoor Attack Sleeper Agent poisoning attack on a neural network trained with TensorFlow. We will be training our data on a subset of the CIFAR-10 dataset. The methods described are derived from [this paper](https://arxiv.org/pdf/2106.08970.pdf) by Hossein Souri, et. al. 2021."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d27f7a",
   "metadata": {},
   "source": [
    "# Data Normalization and Substitute Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "501c126e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-01 13:14:32.647663: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-07-01 13:14:36.941449: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-07-01 13:14:36.942672: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-07-01 13:14:36.958755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:af:00.0 name: Tesla V100-PCIE-32GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2022-07-01 13:14:36.959868: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:d8:00.0 name: Tesla V100-PCIE-32GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2022-07-01 13:14:36.959913: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-07-01 13:14:36.962179: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-07-01 13:14:36.962250: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-07-01 13:14:36.964776: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-07-01 13:14:36.965138: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-07-01 13:14:36.967623: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-07-01 13:14:36.968888: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-07-01 13:14:36.974027: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-07-01 13:14:36.978060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1\n",
      "2022-07-01 13:14:36.978728: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-01 13:14:37.217973: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:af:00.0 name: Tesla V100-PCIE-32GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2022-07-01 13:14:37.219098: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:d8:00.0 name: Tesla V100-PCIE-32GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2022-07-01 13:14:37.219155: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-07-01 13:14:37.219187: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-07-01 13:14:37.219202: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-07-01 13:14:37.219216: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-07-01 13:14:37.219230: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-07-01 13:14:37.219243: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-07-01 13:14:37.219257: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-07-01 13:14:37.219271: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-07-01 13:14:37.222776: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1\n",
      "2022-07-01 13:14:37.222828: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-07-01 13:14:38.164266: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-07-01 13:14:38.164320: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 \n",
      "2022-07-01 13:14:38.164337: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N Y \n",
      "2022-07-01 13:14:38.164343: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   Y N \n",
      "2022-07-01 13:14:38.168407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 24085 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:af:00.0, compute capability: 7.0)\n",
      "2022-07-01 13:14:38.170930: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 30132 MB memory) -> physical GPU (device: 1, name: Tesla V100-PCIE-32GB, pci bus id: 0000:d8:00.0, compute capability: 7.0)\n",
      "2022-07-01 13:14:38.171245: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-07-01 13:14:39.157868: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-07-01 13:14:39.158648: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2200000000 Hz\n",
      "2022-07-01 13:14:39.567321: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-07-01 13:14:39.776490: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-07-01 13:14:41.024527: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256\n",
      "2022-07-01 13:14:41.080325: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 18s 30ms/step - loss: 0.4124 - accuracy: 0.9133\n",
      "Model and data preparation done.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os, sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "module_path = os.path.abspath(os.path.join('.'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from art.estimators.classification import TensorFlowV2Classifier\n",
    "from art.utils import load_cifar10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test), min_, max_ = load_cifar10()\n",
    "\n",
    "mean = np.mean(x_train,axis=(0,1,2,3))\n",
    "std = np.std(x_train,axis=(0,1,2,3))\n",
    "x_train = (x_train-mean)/(std+1e-7)\n",
    "x_test = (x_test-mean)/(std+1e-7)\n",
    "\n",
    "min_ = (min_-mean)/(std+1e-7)\n",
    "max_ = (max_-mean)/(std+1e-7)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tqdm.keras import TqdmCallback\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "# Tweaked the model from https://github.com/calmisential/TensorFlow2.0_ResNet\n",
    "# MIT License\n",
    "def basic_block(x, filter_num, stride=1):\n",
    "    conv1 = tf.keras.layers.Conv2D(filters=filter_num,\n",
    "                                        kernel_size=(3, 3),\n",
    "                                        strides=stride,\n",
    "                                        padding=\"same\")\n",
    "    bn1 = tf.keras.layers.BatchNormalization()\n",
    "    conv2 = tf.keras.layers.Conv2D(filters=filter_num,\n",
    "                                        kernel_size=(3, 3),\n",
    "                                        strides=1,\n",
    "                                        padding=\"same\")\n",
    "    bn2 = tf.keras.layers.BatchNormalization()\n",
    "    if stride != 1:\n",
    "        downsample = tf.keras.Sequential()\n",
    "        downsample.add(tf.keras.layers.Conv2D(filters=filter_num,\n",
    "                                                    kernel_size=(1, 1),\n",
    "                                                    strides=stride))\n",
    "        downsample.add(tf.keras.layers.BatchNormalization())\n",
    "    else:\n",
    "        downsample = tf.keras.layers.Lambda(lambda x: x)\n",
    "\n",
    "    residual = downsample(x)\n",
    "    x = conv1(x)\n",
    "    x = bn1(x)\n",
    "    x = tf.nn.relu(x)\n",
    "    x = conv2(x)\n",
    "    x = bn2(x)\n",
    "    output = tf.nn.relu(tf.keras.layers.add([residual, x]))\n",
    "    return output\n",
    "\n",
    "def basic_block_layer(x, filter_num, blocks, stride=1):\n",
    "    x = basic_block(x, filter_num, stride=stride)\n",
    "    for _ in range(1, blocks):\n",
    "        x = basic_block(x, filter_num, stride=1)\n",
    "    return x\n",
    "\n",
    "def resnet(x, num_classes, layer_params):\n",
    "    pad1 = tf.keras.layers.ZeroPadding2D(padding=1)\n",
    "    conv1 = tf.keras.layers.Conv2D(filters=64,\n",
    "                                        kernel_size=(3, 3),\n",
    "                                        strides=1,\n",
    "                                        padding=\"same\")\n",
    "    bn1 = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    avgpool = tf.keras.layers.GlobalAveragePooling2D()\n",
    "    fc = tf.keras.layers.Dense(units=num_classes, activation=tf.keras.activations.softmax)\n",
    "\n",
    "    x = pad1(x)\n",
    "    x = conv1(x)\n",
    "    x = bn1(x)\n",
    "    x = tf.nn.relu(x)\n",
    "    x = basic_block_layer(x, filter_num=64,\n",
    "                                        blocks=layer_params[0])\n",
    "    x = basic_block_layer(x, filter_num=128,\n",
    "                                        blocks=layer_params[1],\n",
    "                                        stride=2)\n",
    "    x = basic_block_layer(x, filter_num=256,\n",
    "                                        blocks=layer_params[2],\n",
    "                                        stride=2)\n",
    "    x = basic_block_layer(x, filter_num=512,\n",
    "                                        blocks=layer_params[3],\n",
    "                                        stride=2)\n",
    "    x = avgpool(x)\n",
    "    output = fc(x)\n",
    "    return output\n",
    "\n",
    "def resnet_18(x, num_classes):\n",
    "    return resnet(x, num_classes, layer_params=[2, 2, 2, 2])\n",
    "\n",
    "def create_model(x_train, y_train, num_classes=10, batch_size=64, epochs=25, callbacks=[]):\n",
    "    inputs = tf.keras.layers.Input(shape=x_train.shape[1:])  # Specify the dimensions\n",
    "    outputs = resnet_18(inputs, num_classes)\n",
    "    model = tf.keras.models.Model(inputs, outputs)\n",
    "\n",
    "    opt = tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,\n",
    "        samplewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization=False,\n",
    "        zca_whitening=False,\n",
    "        rotation_range=15,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=False\n",
    "        )\n",
    "    \n",
    "    datagen.fit(x_train)\n",
    "    callbacks = callbacks + [TqdmCallback(verbose=0)]\n",
    "    model.fit(datagen.flow(x_train, y_train, batch_size=batch_size), steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs,verbose=0,callbacks=callbacks)\n",
    "    return model\n",
    "    \n",
    "model_path = \"../../../models/cifar10-resnet18-notebook.h5\"\n",
    "if not os.path.exists(model_path):\n",
    "    model = create_model(x_train, y_train, epochs=80)\n",
    "    model.save(model_path)\n",
    "else:\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "model.evaluate(x_test, y_test)\n",
    "K = 1000\n",
    "# input_shape=(K,32, 32, 3)\n",
    "input_shape=(32, 32, 3)\n",
    "model_art = TensorFlowV2Classifier(model, nb_classes=10, input_shape=input_shape)\n",
    "\n",
    "print(\"Model and data preparation done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ce9991",
   "metadata": {},
   "source": [
    "# Load Trigger Patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31e14884",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "from skimage.transform import resize\n",
    "\n",
    "patch_size = 8\n",
    "img = Image.open('trigger_10.png')\n",
    "numpydata = asarray(img)\n",
    "patch = resize(numpydata, (patch_size,patch_size,3))\n",
    "patch = (patch-mean)/(std+1e-7)\n",
    "x_train_orig = np.copy(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268927a7",
   "metadata": {},
   "source": [
    "# Define Source and Target Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "632c4947",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_source = 0\n",
    "class_target = 1\n",
    "K = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb71585f",
   "metadata": {},
   "source": [
    "# Select Triggers from Source Class and helper functions for calculating Success Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5b38a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.utils import to_categorical\n",
    "\n",
    "def select_trigger_train(x_train,y_train,K,class_source,class_target):\n",
    "    x_train_ = np.copy(x_train)\n",
    "    index_source = np.where(y_train.argmax(axis=1)==class_source)[0][0:K]\n",
    "    index_target = np.where(y_train.argmax(axis=1)==class_target)[0]\n",
    "    x_trigger = x_train_[index_source]\n",
    "    y_trigger  = to_categorical([class_target], nb_classes=10)\n",
    "    y_trigger = np.tile(y_trigger,(len(index_source),1))\n",
    "    return x_trigger,y_trigger,index_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfdbf5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trigger,y_trigger,index_target = select_trigger_train(x_train,y_train,K,class_source,class_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a81a2b",
   "metadata": {},
   "source": [
    "# Generate Poison Images through attack "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a43af80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92d4741b718d430ba8903b39545ae360",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adbb490ff6ca4265b289717b636a0598",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0epoch [00:00, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7b18e1b23d54330aea90400e94b8416",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0epoch [00:00, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 0.6093 - accuracy: 0.8814\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a4bb2aa82124a3ea8c0ad452edd979a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0epoch [00:00, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e46d6694061544eaa8ff027ceab37941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0epoch [00:00, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 0.5671 - accuracy: 0.8920\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4852c6f332794ec9b6b668db369f06b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0epoch [00:00, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28094ed35967424985207dc0cb2e1253",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0epoch [00:00, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4666 - accuracy: 0.9033\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c584817535e42dea1edb93d0b9b6dcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0epoch [00:00, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best B-score: 0.01159733533859253\n"
     ]
    }
   ],
   "source": [
    "from art.attacks.poisoning.sleeper_agent_attack import SleeperAgentAttack\n",
    "attack = SleeperAgentAttack(model_art,\n",
    "                                percent_poison=0.10,\n",
    "                                max_trials=1,\n",
    "                                max_epochs=250,\n",
    "                                learning_rate_schedule=(np.array([1e-1, 1e-2, 1e-3, 1e-4, 1e-5]), [250, 350, 400, 430, 460]),\n",
    "                                clip_values=(min_,max_),\n",
    "                                epsilon=16/255 * (max_ - min_),\n",
    "                                batch_size=500,\n",
    "                                verbose=1,\n",
    "                                indices_target=index_target,\n",
    "                                patching_strategy=\"random\",\n",
    "                                selection_strategy=\"max-norm\",\n",
    "                                patch=patch,\n",
    "                                retraining_factor = 4,\n",
    "                                model_retrain = True,\n",
    "                                model_retraining_epoch = 80,\n",
    "                                class_source = class_source,\n",
    "                                class_target = class_target\n",
    "                           )\n",
    "x_poison, y_poison = attack.poison(x_trigger,y_trigger,x_train,y_train,x_test,y_test) \n",
    "indices_poison = attack.get_poison_indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2cc69b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1f9e60e7f63401c8bf5803d0da1bdbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0epoch [00:00, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_poisoned = create_model(x_poison,y_poison,epochs=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c2ef56",
   "metadata": {},
   "source": [
    "# Visualize Trigger, Original and Poisoned Images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f132a457",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_trigger[0]*(std+1e-7)+mean)\n",
    "plt.title('Trigger image')\n",
    "plt.show()\n",
    "\n",
    "index_poisoned_example = np.where([np.any(p!=o) for (p,o) in zip(x_poison,x_train)])[0]\n",
    "plt.imshow(x_train_orig[index_target[indices_poison][0]]*(std+1e-7)+mean)\n",
    "plt.title('Original image')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(x_poison[index_target[indices_poison][0]]*(std+1e-7)+mean)\n",
    "plt.title('Poisoned image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06b2eec",
   "metadata": {},
   "source": [
    "# Calculate Success Rate on x_train and x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be07271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_trigger_patch(x_set,patch_type=\"fixed\"):\n",
    "    img = Image.open('trigger_10.png')\n",
    "    numpydata = asarray(img)\n",
    "    patch = resize(numpydata, (8,8,3))\n",
    "    patch = (patch-mean)/(std+1e-7)\n",
    "    if patch_type == \"fixed\":\n",
    "        x_set[:,-patch_size:,-patch_size:,:] = patch\n",
    "    else:\n",
    "        for x in x_set:\n",
    "            x_cord = random.randrange(0,x.shape[1] - patch.shape[1] + 1)\n",
    "            y_cord = random.randrange(0,x.shape[2] - patch.shape[2] + 1)\n",
    "            x[x_cord:x_cord+patch_size,y_cord:y_cord+patch_size,:]=patch\n",
    "\n",
    "    return x_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbf2c18",
   "metadata": {},
   "source": [
    "# Calculate on train images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20a095d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "index_source_train = np.where(y_train.argmax(axis=1)==class_source)[0]\n",
    "x_train_trigger = x_train_orig[index_source_train]\n",
    "x_train_trigger = add_trigger_patch(x_train_trigger,\"random\")\n",
    "result_poisoned_train = model_poisoned(x_train_trigger)\n",
    "print(len(result_poisoned_train))\n",
    "\n",
    "success_train = (np.argmax(result_poisoned_train,axis=1)==1).sum()/result_poisoned_train.shape[0]\n",
    "print(\"Train Success Rate\",success_train)\n",
    "plt.imshow(x_train_trigger[0]*(std+1e-7)+mean)\n",
    "plt.title('Trigger image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a0b8e7",
   "metadata": {},
   "source": [
    "# Calculate Success Rate on Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5fcfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "index_source_test = np.where(y_test.argmax(axis=1)==class_source)[0]\n",
    "x_test_trigger = x_test[index_source_test]\n",
    "x_test_trigger = add_trigger_patch(x_test_trigger,\"random\")\n",
    "result_poisoned_test = model_poisoned(x_test_trigger)\n",
    "print(len(result_poisoned_test))\n",
    "\n",
    "success_test = (np.argmax(result_poisoned_test,axis=1)==1).sum()/result_poisoned_test.shape[0]\n",
    "print(\"Test Success Rate:\",success_test)\n",
    "\n",
    "plt.imshow(x_test_trigger[0]*(std+1e-7)+mean)\n",
    "plt.title('Trigger image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b80bf0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed43558",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15462b40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
