{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "167d8f6c",
   "metadata": {},
   "source": [
    "# This notebook implements sleeper agent attack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fc35bd",
   "metadata": {},
   "source": [
    "In this notebook, we will learn how to use ART to run a Hidden Trigger Backdoor Attack Sleeper Agent poisoning attack on a neural network trained with TensorFlow. We will be training our data on a subset of the CIFAR-10 dataset. The methods described are derived from [this paper](https://arxiv.org/pdf/2106.08970.pdf) by Hossein Souri, et. al. 2021."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43833c00",
   "metadata": {},
   "source": [
    "# Data Normalization and Substitute Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6de8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "module_path = os.path.abspath(os.path.join('.'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2824b62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-12 15:41:32.318648: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-09-12 15:41:36.303959: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-09-12 15:41:36.305575: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-09-12 15:41:36.316287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:81:00.0 name: Tesla V100-PCIE-32GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2022-09-12 15:41:36.316523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:82:00.0 name: Tesla V100-PCIE-32GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2022-09-12 15:41:36.316547: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-09-12 15:41:36.318508: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-09-12 15:41:36.318549: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-09-12 15:41:36.320584: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-09-12 15:41:36.320874: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-09-12 15:41:36.322993: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-09-12 15:41:36.324046: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-09-12 15:41:36.328460: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-09-12 15:41:36.329295: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1\n",
      "2022-09-12 15:41:36.329684: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-12 15:41:36.618086: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:81:00.0 name: Tesla V100-PCIE-32GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2022-09-12 15:41:36.618351: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:82:00.0 name: Tesla V100-PCIE-32GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2022-09-12 15:41:36.618398: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-09-12 15:41:36.618442: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-09-12 15:41:36.618466: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-09-12 15:41:36.618506: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-09-12 15:41:36.618528: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-09-12 15:41:36.618551: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-09-12 15:41:36.618573: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-09-12 15:41:36.618596: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-09-12 15:41:36.619461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1\n",
      "2022-09-12 15:41:36.619500: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-09-12 15:41:37.935858: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-09-12 15:41:37.935915: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 \n",
      "2022-09-12 15:41:37.935934: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N Y \n",
      "2022-09-12 15:41:37.935939: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   Y N \n",
      "2022-09-12 15:41:37.937217: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 26123 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:81:00.0, compute capability: 7.0)\n",
      "2022-09-12 15:41:37.938009: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 16721 MB memory) -> physical GPU (device: 1, name: Tesla V100-PCIE-32GB, pci bus id: 0000:82:00.0, compute capability: 7.0)\n",
      "2022-09-12 15:41:37.938746: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D\n",
    "\n",
    "from art.attacks.evasion import FeatureAdversariesTensorFlowV2\n",
    "from art.estimators.classification import TensorFlowV2Classifier\n",
    "from art.utils import load_mnist\n",
    "from art.utils import load_cifar10\n",
    "\n",
    "# Step 1: Load the MNIST dataset\n",
    "\n",
    "(x_train, y_train), (x_test, y_test), min_, max_ = load_cifar10()\n",
    "\n",
    "# Step 1a: Cast to np.float32\n",
    "x_train = x_train.astype(np.float32)\n",
    "x_test = x_test.astype(np.float32)\n",
    "\n",
    "mean = np.mean(x_train,axis=(0,1,2,3))\n",
    "std = np.std(x_train,axis=(0,1,2,3))\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tqdm.keras import TqdmCallback\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "# Tweaked the model from https://github.com/calmisential/TensorFlow2.0_ResNet\n",
    "# MIT License\n",
    "def basic_block(x, filter_num, stride=1):\n",
    "    conv1 = tf.keras.layers.Conv2D(filters=filter_num,\n",
    "                                        kernel_size=(3, 3),\n",
    "                                        strides=stride,\n",
    "                                        padding=\"same\")\n",
    "    bn1 = tf.keras.layers.BatchNormalization()\n",
    "    conv2 = tf.keras.layers.Conv2D(filters=filter_num,\n",
    "                                        kernel_size=(3, 3),\n",
    "                                        strides=1,\n",
    "                                        padding=\"same\")\n",
    "    bn2 = tf.keras.layers.BatchNormalization()\n",
    "    if stride != 1:\n",
    "        downsample = tf.keras.Sequential()\n",
    "        downsample.add(tf.keras.layers.Conv2D(filters=filter_num,\n",
    "                                                    kernel_size=(1, 1),\n",
    "                                                    strides=stride))\n",
    "        downsample.add(tf.keras.layers.BatchNormalization())\n",
    "    else:\n",
    "        downsample = tf.keras.layers.Lambda(lambda x: x)\n",
    "\n",
    "    residual = downsample(x)\n",
    "    x = conv1(x)\n",
    "    x = bn1(x)\n",
    "    x = tf.nn.relu(x)\n",
    "    x = conv2(x)\n",
    "    x = bn2(x)\n",
    "    output = tf.nn.relu(tf.keras.layers.add([residual, x]))\n",
    "    return output\n",
    "\n",
    "def basic_block_layer(x, filter_num, blocks, stride=1):\n",
    "    x = basic_block(x, filter_num, stride=stride)\n",
    "    for _ in range(1, blocks):\n",
    "        x = basic_block(x, filter_num, stride=1)\n",
    "    return x\n",
    "\n",
    "def resnet(x, num_classes, layer_params):\n",
    "    pad1 = tf.keras.layers.ZeroPadding2D(padding=1)\n",
    "    conv1 = tf.keras.layers.Conv2D(filters=64,\n",
    "                                        kernel_size=(3, 3),\n",
    "                                        strides=1,\n",
    "                                        padding=\"same\")\n",
    "    bn1 = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    avgpool = tf.keras.layers.GlobalAveragePooling2D()\n",
    "    fc = tf.keras.layers.Dense(units=num_classes, activation=tf.keras.activations.softmax)\n",
    "\n",
    "    x = pad1(x)\n",
    "    x = conv1(x)\n",
    "    x = bn1(x)\n",
    "    x = tf.nn.relu(x)\n",
    "    x = basic_block_layer(x, filter_num=64,\n",
    "                                        blocks=layer_params[0])\n",
    "    x = basic_block_layer(x, filter_num=128,\n",
    "                                        blocks=layer_params[1],\n",
    "                                        stride=2)\n",
    "    x = basic_block_layer(x, filter_num=256,\n",
    "                                        blocks=layer_params[2],\n",
    "                                        stride=2)\n",
    "    x = basic_block_layer(x, filter_num=512,\n",
    "                                        blocks=layer_params[3],\n",
    "                                        stride=2)\n",
    "    x = avgpool(x)\n",
    "    output = fc(x)\n",
    "    return output\n",
    "\n",
    "def resnet_18(x, num_classes):\n",
    "    return resnet(x, num_classes, layer_params=[2, 2, 2, 2])\n",
    "\n",
    "\n",
    "# # Step 2: Create the model\n",
    "inputs = tf.keras.layers.Input(shape=x_train.shape[1:])  # Specify the dimensions\n",
    "outputs = resnet_18(inputs, 10)\n",
    "model = tf.keras.models.Model(inputs, outputs)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# # Step 2a: Define the loss function and optimizer\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "loss_object = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "def train_step(model, images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images, training=True)\n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "# Step 3: Create the ART classifier\n",
    "\n",
    "model_art = TensorFlowV2Classifier(\n",
    "    model=model,\n",
    "    loss_object=loss_object,\n",
    "    train_step=train_step,\n",
    "    nb_classes=10,\n",
    "    input_shape=x_train.shape[1:],\n",
    "    clip_values=(min_, max_),\n",
    "    preprocessing=(mean,std)\n",
    ")\n",
    "\n",
    "# Step 4: Train the ART classifier\n",
    "\n",
    "# model_art.fit(x_train, y_train, batch_size=128, nb_epochs=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48f734de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and data preparation done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-12 15:41:53.006000: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-09-12 15:41:54.050668: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on benign test examples: 60.24%\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('tf_resnet.h5')\n",
    "# optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "# loss_object = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "model_art = TensorFlowV2Classifier(model, nb_classes=10, input_shape=x_train.shape[1:], \n",
    "                                   clip_values=(min_,max_), preprocessing=(mean,std))\n",
    "print(\"Model and data preparation done.\")\n",
    "predictions = model_art.predict(x_test)\n",
    "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
    "print(\"Accuracy on benign test examples: {}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fada24",
   "metadata": {},
   "source": [
    "# Load Trigger Patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7b176ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "from skimage.transform import resize\n",
    "\n",
    "patch_size = 8\n",
    "img = Image.open('trigger_10.png')\n",
    "numpydata = asarray(img)\n",
    "patch = resize(numpydata, (patch_size,patch_size,3))\n",
    "x_train_orig = np.copy(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80937d67",
   "metadata": {},
   "source": [
    "# Define Source and Target Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21fe22e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_source = 0\n",
    "class_target = 1\n",
    "K = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444cb863",
   "metadata": {},
   "source": [
    "# Select Triggers from Source Class and helper functions for calculating Success Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5009e7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.utils import to_categorical\n",
    "\n",
    "def select_trigger_train(x_train,y_train,K,class_source,class_target):\n",
    "    x_train_ = np.copy(x_train)\n",
    "    index_source = np.where(y_train.argmax(axis=1)==class_source)[0][0:K]\n",
    "    index_target = np.where(y_train.argmax(axis=1)==class_target)[0]\n",
    "    x_trigger = x_train_[index_source]\n",
    "    y_trigger  = to_categorical([class_target], nb_classes=10)\n",
    "    y_trigger = np.tile(y_trigger,(len(index_source),1))\n",
    "    return x_trigger,y_trigger,index_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f74f95b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trigger,y_trigger,index_target = select_trigger_train(x_train,y_train,K,class_source,class_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee9f56b",
   "metadata": {},
   "source": [
    "# Generate Poison Images through attack "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "47e18090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bd8c5422e934568bc9d394f1eea09d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ad5eae3e8cb4fb5a4c6786cc8037777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0epoch [00:00, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from art.attacks.poisoning.sleeper_agent_attack import SleeperAgentAttack\n",
    "attack = SleeperAgentAttack(model_art,\n",
    "                                percent_poison=0.01,\n",
    "                                max_trials=1,\n",
    "                                max_epochs=250,\n",
    "                                learning_rate_schedule=(np.array([1e-1, 1e-2, 1e-3, 1e-4, 1e-5]), [250, 350, 400, 430, 460]),\n",
    "                                clip_values=(min_,max_),\n",
    "                                epsilon=16,\n",
    "                                batch_size=500,\n",
    "                                verbose=1,\n",
    "                                indices_target=index_target,\n",
    "                                patching_strategy=\"random\",\n",
    "                                selection_strategy=\"max-norm\",\n",
    "                                patch=patch,\n",
    "                                retraining_factor = 4,\n",
    "                                model_retrain = False,\n",
    "                                model_retraining_epoch = 80,\n",
    "                                class_source = class_source,\n",
    "                                class_target = class_target\n",
    "                           )\n",
    "x_poison, y_poison = attack.poison(x_trigger,y_trigger,x_train,y_train,x_test,y_test) \n",
    "indices_poison = attack.get_poison_indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0778d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_poisoned = TensorFlowV2Classifier(\n",
    "    model=model,\n",
    "    loss_object=loss_object,\n",
    "    train_step=train_step,\n",
    "    nb_classes=10,\n",
    "    input_shape=x_poison.shape[1:],\n",
    "    clip_values=(min_, max_),\n",
    "    preprocessing=(mean,std)\n",
    ")\n",
    "\n",
    "# Step 4: Train the ART classifier\n",
    "model_poisoned.fit(x_poison, y_poison, batch_size=128, nb_epochs=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afd72ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_poisoned.predict(x_test)\n",
    "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
    "print(\"Accuracy on benign test examples: {}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81c574d",
   "metadata": {},
   "source": [
    "# Visualize Trigger, Original and Poisoned Images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4dee10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_trigger[0])\n",
    "plt.title('Trigger image')\n",
    "plt.show()\n",
    "\n",
    "index_poisoned_example = np.where([np.any(p!=o) for (p,o) in zip(x_poison,x_train)])[0]\n",
    "plt.imshow(x_train_orig[index_target[indices_poison][0]])\n",
    "plt.title('Original image')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(x_poison[index_target[indices_poison][0]])\n",
    "plt.title('Poisoned image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16f659e",
   "metadata": {},
   "source": [
    "# Calculate Success Rate on x_train and x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af89043",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_trigger_patch(x_set,patch_type=\"fixed\"):\n",
    "    img = Image.open('trigger_10.png')\n",
    "    numpydata = asarray(img)\n",
    "    patch = resize(numpydata, (8,8,3))\n",
    "#     patch = (patch-mean)/std\n",
    "    if patch_type == \"fixed\":\n",
    "        x_set[:,-patch_size:,-patch_size:,:] = patch\n",
    "    else:\n",
    "        for x in x_set:\n",
    "            x_cord = random.randrange(0,x.shape[0] - patch.shape[0] + 1)\n",
    "            y_cord = random.randrange(0,x.shape[1] - patch.shape[1] + 1)\n",
    "            x[x_cord:x_cord+patch_size,y_cord:y_cord+patch_size,:]=patch\n",
    "\n",
    "    return x_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621c1125",
   "metadata": {},
   "source": [
    "# Calculate on train images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeeeabe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "index_source_train = np.where(y_train.argmax(axis=1)==class_source)[0]\n",
    "x_train_trigger = x_train_orig[index_source_train]\n",
    "x_train_trigger = add_trigger_patch(x_train_trigger,\"random\")\n",
    "result_poisoned_train = model_poisoned.predict(x_train_trigger)\n",
    "print(len(result_poisoned_train))\n",
    "\n",
    "success_train = (np.argmax(result_poisoned_train,axis=1)==class_target).sum()/result_poisoned_train.shape[0]\n",
    "print(\"Train Success Rate\",success_train)\n",
    "plt.imshow(x_train_trigger[0])\n",
    "plt.title('Trigger image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81852c0",
   "metadata": {},
   "source": [
    "# Calculate Success Rate on Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d942568f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "index_source_test = np.where(y_test.argmax(axis=1)==class_source)[0]\n",
    "x_test_trigger = x_test[index_source_test]\n",
    "x_test_trigger = add_trigger_patch(x_test_trigger,\"random\")\n",
    "result_poisoned_test = model_poisoned.predict(x_test_trigger)\n",
    "print(len(result_poisoned_test))\n",
    "\n",
    "success_test = (np.argmax(result_poisoned_test,axis=1)==class_target).sum()/result_poisoned_test.shape[0]\n",
    "print(\"Test Success Rate:\",success_test)\n",
    "\n",
    "plt.imshow(x_test_trigger[0])\n",
    "plt.title('Trigger image')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
