{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## White Box on MNIST (Table 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "table = []\n",
    "DEFENSES = ['Feature squeezing',\n",
    "               'Label smoothing',\n",
    "               'FGSM Adversrial Training',\n",
    "               'VAT',\n",
    "               'Gaussian + BRELU ',\n",
    "               'Gaussian + RELU',\n",
    "               'Vanilla CNN'\n",
    "           ]\n",
    "for d in range(len(DEFENSES)):\n",
    "    table.append([DEFENSES[d]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import json\n",
    "import os, sys\n",
    "from os.path import join, exists\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from config import DATA_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### White box on adversarial examples frm Deepfool for MNIST test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CLASSIFIERS = [#\"cnn/relu/featsqueeze1\", #Feature Squeezing\n",
    "               #\"cnn/relu/labsmooth\", # Label Smoothing\n",
    "               #\"cnn/relu/adv-trained/fgsm/eps0.30_train.npy\", # Adversarial training FGSM eps=0.4\n",
    "               #\"cnn/relu/adv-trained/vat/eps2.10_train.npy\",  # Adversarial Training VAT eps=2.1\n",
    "               \"cnn/brelu/gaussian/stdev0.30/pert-insts10\"] # Gaussian sigma =0.3 + brelu\n",
    "               #\"cnn/relu/gaussian/stdev0.30/pert-insts10\",  # Gaussian sigma =0.3 + relu\n",
    "               #\"cnn/relu\"]  # vanilla cnn-relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INPUT_PATH = join(DATA_PATH, 'classifiers','mnist')\n",
    "for c in CLASSIFIERS:\n",
    "    assert exists(join(INPUT_PATH, c, \"best-weights.h5\"))\n",
    "    assert exists(join(INPUT_PATH, c, \"model.json\"))\n",
    "    assert exists(join(INPUT_PATH, c, \"params.json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adversarial Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn/brelu/gaussian/stdev0.30/pert-insts10\n"
     ]
    }
   ],
   "source": [
    "WBox_ATTACKS = join(DATA_PATH,\"adversarial\",'mnist')\n",
    "\n",
    "ADV_IMAGES = [#\"cnn/relu/featsqueeze1\", #Feature Squeezing\n",
    "              # \"cnn/relu/labsmooth\", # Label Smoothing\n",
    "              # \"cnn/relu/adv-trained/fgsm/eps0.30_train\", # Adversarial training FGSM eps=0.4\n",
    "              # \"cnn/relu/adv-trained/vat/eps2.10_train\",  # Adversarial Training VAT eps=2.1\n",
    "               \"cnn/brelu/gaussian/stdev0.30/pert-insts10\"] # Gaussian sigma =0.3 + brelu\n",
    "              # \"cnn/relu/gaussian/stdev0.30/pert-insts10\",  # Gaussian sigma =0.3 + relu\n",
    "              # \"cnn/relu\"]  # vanilla cnn-relu\n",
    "for c in ADV_IMAGES[0:]:\n",
    "    print(c)\n",
    "    #assert exists(join(WBox_ATTACKS, c, \"fgsm\", \"eps0.10_test.npy\"))\n",
    "    assert exists(join(WBox_ATTACKS, c, \"deepfool\", \"test.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Classifiers\n",
    "from art.classifiers.cnn import CNN\n",
    "from art.classifiers.utils import load_classifier\n",
    "from art.utils import load_mnist\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "#important for ensuring the model_weights are loaded in the same session as the one where metrics are computed\n",
    "session = tf.Session()\n",
    "K.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X_train,_), (X_test, Y_test) = load_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9013 10000\n",
      "nan\n",
      "nan\n",
      "9.22288\n",
      "Feature squeezing nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ncnn/relu/featsqueeze1 0.161807\\ncnn/relu/labsmooth 0.183515\\ncnn/relu/adv-trained/fgsm/eps0.30_train.npy 0.132598\\ncnn/relu/adv-trained/vat/eps2.10_train.npy 0.0876128\\ncnn/brelu/gaussian/stdev0.30/pert-insts10 0.228296\\ncnn/relu/gaussian/stdev0.30/pert-insts10 0.0665115\\ncnn/relu 0.177879\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from art.metrics import empirical_robustness_df\n",
    "\n",
    "for c,a,d in zip(CLASSIFIERS,ADV_IMAGES,range(len(DEFENSES))):\n",
    "    classifier = load_classifier(join(INPUT_PATH, c),'best-weights.h5')\n",
    "    attack_imgs = np.load(join(WBox_ATTACKS, a, \"deepfool\", \"test.npy\"))\n",
    "    emp_robust = empirical_robustness_df(X_test, attack_imgs, classifier.model, session)\n",
    "\n",
    "    temp = table[d]\n",
    "    temp.append(emp_robust)\n",
    "    table[d] = temp\n",
    "    print(DEFENSES[d],emp_robust)\n",
    "'''\n",
    "cnn/relu/featsqueeze1 0.161807\n",
    "cnn/relu/labsmooth 0.183515\n",
    "cnn/relu/adv-trained/fgsm/eps0.30_train.npy 0.132598\n",
    "cnn/relu/adv-trained/vat/eps2.10_train.npy 0.0876128\n",
    "cnn/brelu/gaussian/stdev0.30/pert-insts10 0.228296\n",
    "cnn/relu/gaussian/stdev0.30/pert-insts10 0.0665115\n",
    "cnn/relu 0.177879\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature squeezing 10.1700000428\n"
     ]
    }
   ],
   "source": [
    "# get classifier\n",
    "for c,a,d in zip(CLASSIFIERS,ADV_IMAGES,range(len(DEFENSES))):\n",
    "    classifier = load_classifier(join(INPUT_PATH, c),'best-weights.h5')\n",
    "    attack_imgs = np.load(join(WBox_ATTACKS, a, \"deepfool\", \"test.npy\"))\n",
    "    acc = classifier.evaluate(x_val=attack_imgs,y_val=Y_test,batch_size=100,verbose=0)[1]*100\n",
    "    \n",
    "    temp = table[d]\n",
    "    temp.append(acc)\n",
    "    table[d] = temp\n",
    "    print(DEFENSES[d],acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Robustness as measured by proximty of decision boundary to training examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Feature squeezing 2.35806\n",
      "Label smoothing 2.26037\n",
      "FGSM Adversrial Training 2.88795\n",
      "VAT 2.90772\n",
      "Gaussian + BRELU  nan\n",
      "Gaussian + RELU 2.76026\n",
      "Vanilla CNN 2.31171\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ncnn/relu/featsqueeze1 10.3774\\ncnn/relu/labsmooth 10.3338\\ncnn/relu/adv-trained/fgsm/eps0.30_train.npy 3.93939\\ncnn/relu/adv-trained/vat/eps2.10_train.npy 5.41566\\ncnn/brelu/gaussian/stdev0.30/pert-insts10 16.9473\\ncnn/relu/gaussian/stdev0.30/pert-insts10 10.3566\\ncnn/relu 10.5697\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from art.metrics import nearest_nieghbour_dist_df\n",
    "\n",
    "params = {\"eps_step\": 0.05,\n",
    "        \"eps_max\": 1.0,\n",
    "        \"clip_min\": 0.0,\n",
    "        \"clip_max\": 1.0}\n",
    "\n",
    "for c,a,d in zip(CLASSIFIERS,ADV_IMAGES,range(len(DEFENSES))):\n",
    "    classifier = load_classifier(join(INPUT_PATH, c),'best-weights.h5')\n",
    "    attack_imgs = np.load(join(WBox_ATTACKS, a, \"deepfool\", \"test.npy\"))\n",
    "    avg_nn_dist = nearest_nieghbour_dist_df(X_test, attack_imgs,classifier.model, X_train,  session)\n",
    "    \n",
    "    temp = table[d]\n",
    "    temp.append(avg_nn_dist)\n",
    "    table[d] = temp\n",
    "    print(DEFENSES[d],avg_nn_dist)\n",
    "    \n",
    "\n",
    "\n",
    "'''\n",
    "cnn/relu/featsqueeze1 10.3774\n",
    "cnn/relu/labsmooth 10.3338\n",
    "cnn/relu/adv-trained/fgsm/eps0.30_train.npy 3.93939\n",
    "cnn/relu/adv-trained/vat/eps2.10_train.npy 5.41566\n",
    "cnn/brelu/gaussian/stdev0.30/pert-insts10 16.9473\n",
    "cnn/relu/gaussian/stdev0.30/pert-insts10 10.3566\n",
    "cnn/relu 10.5697\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrr}\n",
      "\\hline\n",
      " Feature squeezing        & 97.23 &   0.179859  &   2.35806 \\\\\n",
      " Label smoothing          & 73.13 &   0.147644  &   2.26037 \\\\\n",
      " FGSM Adversrial Training & 98.26 &   0.0264963 &   2.88795 \\\\\n",
      " VAT                      & 98.41 &   0.021176  &   2.90772 \\\\\n",
      " Gaussian + BRELU         &  9.97 & nan         & nan       \\\\\n",
      " Gaussian + RELU          & 97.07 &   0.105449  &   2.76026 \\\\\n",
      " Vanilla CNN              & 79.16 &   0.155866  &   2.31171 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "print(tabulate(table,tablefmt=\"latex\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Flips wrt: true  3561  pred  3390\n",
    " 9888/10000 [============================>.] - ETA: 0sFeature squeezing 35.61\n",
    "Flips wrt: true  3706  pred  3547\n",
    " 9888/10000 [============================>.] - ETA: 0sLabel smoothing 37.06\n",
    "Flips wrt: true  6136  pred  6027\n",
    " 9888/10000 [============================>.] - ETA: 0sFGSM Adversrial Training 61.36\n",
    "Flips wrt: true  8865  pred  8791\n",
    " 9888/10000 [============================>.] - ETA: 0sVAT 88.65\n",
    "Flips wrt: true  9073  pred  9061\n",
    " 9888/10000 [============================>.] - ETA: 0sGaussian + BRELU  90.73\n",
    "Flips wrt: true  9826  pred  9827\n",
    " 9888/10000 [============================>.] - ETA: 0sGaussian + RELU 98.26\n",
    "Flips wrt: true  5549  pred  5448\n",
    " 9856/10000 [============================>.] - ETA: 0sVanilla CNN 55.49\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for c,a,d in zip(CLASSIFIERS,ADV_IMAGES,range(len(DEFENSES))):\n",
    "    attack_imgs = np.load(join(WBox_ATTACKS, a, \"deepfool\", \"test.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        ..., \n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]]],\n",
       "\n",
       "\n",
       "       [[[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        ..., \n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]]],\n",
       "\n",
       "\n",
       "       [[[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        ..., \n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]]],\n",
       "\n",
       "\n",
       "       ..., \n",
       "       [[[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        ..., \n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]]],\n",
       "\n",
       "\n",
       "       [[[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        ..., \n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]]],\n",
       "\n",
       "\n",
       "       [[[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        ..., \n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]]]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attack_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 214400\r\n",
      "-rw-r--r-- 1 vzantede users       154 Jul 20 11:37 readme.txt\r\n",
      "-rw-r--r-- 1 vzantede users  31360096 Jul 20 14:56 test.npy\r\n",
      "-rw-r--r-- 1 vzantede users 188160096 Jul 20 14:56 train.npy\r\n"
     ]
    }
   ],
   "source": [
    "ls -l /dccstor/dlw/data/adversarial_learning/adversarial/mnist/cnn/brelu/gaussian/stdev0.30/pert-insts10/deepfool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        ..., \n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]]],\n",
       "\n",
       "\n",
       "       [[[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        ..., \n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]]],\n",
       "\n",
       "\n",
       "       [[[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        ..., \n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]]],\n",
       "\n",
       "\n",
       "       ..., \n",
       "       [[[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        ..., \n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]]],\n",
       "\n",
       "\n",
       "       [[[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        ..., \n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]]],\n",
       "\n",
       "\n",
       "       [[[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        ..., \n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]],\n",
       "\n",
       "        [[ nan],\n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         ..., \n",
       "         [ nan],\n",
       "         [ nan],\n",
       "         [ nan]]]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('/dccstor/dlw/data/adversarial_learning/adversarial/mnist/cnn/brelu/gaussian/stdev0.30/pert-insts10/deepfool/test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}