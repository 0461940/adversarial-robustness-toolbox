{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f6145ce-083e-4213-af7a-9f51804b2d4a",
   "metadata": {},
   "source": [
    "# Certified Training using Zonotopes with DeepZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8229684f-9136-4e08-8743-a76600a3880f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "# import sys\n",
    "# sys.path.append('../')\n",
    "from torch import nn\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from art.estimators.certification import deep_z\n",
    "from art.utils import load_mnist, preprocess, to_categorical\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92b485c-7010-4315-a5d8-c9a59b08d7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We make an example pytorch classifier\n",
    "\n",
    "class MNISTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1,\n",
    "                               out_channels=16,\n",
    "                               kernel_size=(4, 4),\n",
    "                               dilation=(1, 1),\n",
    "                               padding=(0, 0),\n",
    "                               stride=(2, 2))\n",
    "        self.conv2 = nn.Conv2d(in_channels=16,\n",
    "                               out_channels=32,\n",
    "                               dilation=(1, 1),\n",
    "                               padding=(0, 0),\n",
    "                               kernel_size=(4, 4),\n",
    "                               stride=(2, 2))\n",
    "        self.fc1 = nn.Linear(in_features=800,\n",
    "                             out_features=1000)\n",
    "        self.fc2 = nn.Linear(in_features=1000,\n",
    "                             out_features=10)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        if isinstance(x, np.ndarray):\n",
    "            x = torch.from_numpy(x).float().to(device)\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c743dd9b-7800-4777-9bdd-f0298db2942f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNISTModel()\n",
    "model = model.to(device)\n",
    "opt = optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "(x_train, y_train), (x_test, y_test), min_, max_ = load_mnist()\n",
    "\n",
    "x_test = np.squeeze(x_test)\n",
    "x_test = np.expand_dims(x_test, axis=1)\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "x_train = np.squeeze(x_train)\n",
    "x_train = np.expand_dims(x_train, axis=1)\n",
    "y_train = np.argmax(y_train, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5146d2-8b04-4968-9d9f-409f2bf3cba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model normally\n",
    "\n",
    "def standard_train(model, opt, criterion, x, y, bsize=32, epochs=5):\n",
    "    num_of_batches = int(len(x) / bsize)\n",
    "    for epoch in range(epochs):\n",
    "        x, y = shuffle(x, y)\n",
    "        loss_list = []\n",
    "        for bnum in range(num_of_batches):\n",
    "            x_batch = np.copy(x[bnum * bsize:(bnum + 1) * bsize])\n",
    "            y_batch = np.copy(y[bnum * bsize:(bnum + 1) * bsize])\n",
    "\n",
    "            x_batch = torch.from_numpy(x_batch).float().to(device)\n",
    "            y_batch = torch.from_numpy(y_batch).type(torch.LongTensor).to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            opt.zero_grad()\n",
    "            outputs = model(x_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss_list.append(loss.data.cpu().detach().numpy())\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        print('End of epoch {} loss {}'.format(epoch, np.mean(loss_list)))\n",
    "    return model\n",
    "\n",
    "model = standard_train(model=model,\n",
    "                       opt=opt,\n",
    "                       criterion=criterion,\n",
    "                       x=x_train,\n",
    "                       y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac5fd81-fb23-4d00-a550-caa38fd1ebbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets now get the predicions for the MNIST test set and see how well our model is doing.\n",
    "with torch.no_grad():\n",
    "    test_preds = model(torch.from_numpy(x_test).float().to(device))\n",
    "\n",
    "test_preds = np.argmax(test_preds.cpu().detach().numpy(), axis=1)\n",
    "print('Test acc: ', np.mean(test_preds == y_test) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4a4cc5-5ca0-41eb-982a-3e9feb055661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# But how robust are these predictions? \n",
    "# We can now examine this neural network's certified robustness. \n",
    "# We pass it into PytorchDeepZ. We will get a print out showing which \n",
    "# neural network layers have been registered. There will also be a \n",
    "# warning to tell us that PytorchDeepZ currently infers a reshape when \n",
    "# a neural network goes from using convolutional to dense layers. \n",
    "# This will cover the majority of use cases, however, if not then the \n",
    "# certification layers in art.estimators.certification.deepz.deep_z.py \n",
    "# can be used to directly build a certified model structure.\n",
    "\n",
    "zonotope_model = deep_z.PytorchDeepZ(model=model, \n",
    "                                     clip_values=(0, 1),\n",
    "                                     optimizer = optim.Adam(model.parameters(), lr=1e-4),\n",
    "                                     loss=nn.CrossEntropyLoss(), \n",
    "                                     input_shape=(1, 28, 28), \n",
    "                                     nb_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7b0b1a-76e8-40ef-b919-7a686eef8ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets now see how robust our model is!\n",
    "# First we need to define what bound we need to check. \n",
    "# Here let's check for L infinity robustness with small bound of 0.05\n",
    "\n",
    "# lets now loop over the data to check its certified robustness:\n",
    "# we need to consider a single sample at a time as due to memory and compute footprints batching is not supported.\n",
    "# In this demo we will look at the first 50 samples of the MNIST test data.\n",
    "\n",
    "original_x = np.copy(x_test)\n",
    "def certification_loop(x, y, preds, bound):\n",
    "    num_certified = 0\n",
    "    num_correct = 0\n",
    "    for i, (sample, pred, label) in enumerate(zip(x[:50], preds[:50], y[:50])):\n",
    "\n",
    "        # we make the matrix representing the allowable perturbations. \n",
    "        # we have 28*28 features and each one can be manipulated independently requiring a different row.\n",
    "        # hence a 784*784 matrix.\n",
    "        eps_bound = np.eye(784) * bound\n",
    "\n",
    "        # we then need to adjust the raw data with the eps bounds to take into account\n",
    "        # the allowable range of 0 - 1 for pixel data.\n",
    "        # We provide a simple function to do this preprocessing for image data.\n",
    "        # However if your use case is not supported then a custom pre-processor function will need to be written.\n",
    "        sample, eps_bound = zonotope_model.pre_process(cent=sample, \n",
    "                                                       eps=eps_bound)\n",
    "        sample = np.expand_dims(sample, axis=0)\n",
    "\n",
    "        # We pass the data sample and the eps bound to the certifier along with the prediction that was made\n",
    "        # for the datapoint. \n",
    "        # A boolean is returned signifying if it can have its class changed under the given bound.\n",
    "        is_certified = zonotope_model.certify(cent=sample,\n",
    "                                              eps=eps_bound,\n",
    "                                              prediction=pred)\n",
    "\n",
    "        if pred == label:\n",
    "            num_correct +=1\n",
    "            if is_certified:\n",
    "                num_certified +=1 \n",
    "\n",
    "        print('Classified Correct {}/{} and also certified {}/{}'.format(num_correct, i+1, num_certified, i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d0ea51",
   "metadata": {},
   "outputs": [],
   "source": [
    "certification_loop(x=np.copy(x_test),\n",
    "                   y=y_test,\n",
    "                   preds=test_preds,\n",
    "                   bound=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e25ac62-b575-468d-99d6-55d069e16731",
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.defences.trainer import AdversarialTrainerCertified\n",
    "\n",
    "# We will now train the model to improve its certified accuracy. \n",
    "# Regular PGD training will boost certified performance, however even higher certification scores can \n",
    "# be obtained by training the nerual network with the objective of certified performance. \n",
    "\n",
    "# NB! Certified Adversarial training takes about X hours on an NVIDIA V100 with the following parameters.\n",
    "\n",
    "pgd_params = {\"eps\": 0.3,\n",
    "              \"eps_step\": 0.05,\n",
    "              \"max_iter\": 20,\n",
    "              \"num_random_init\": 1,\n",
    "              \"batch_size\": 32,}\n",
    "\n",
    "trainer = AdversarialTrainerCertified(zonotope_model,\n",
    "                                      pgd_params=pgd_params,\n",
    "                                      batch_size=10,\n",
    "                                      bound=0.15)\n",
    "\n",
    "trainer.fit(x_train,\n",
    "            y_train,\n",
    "            nb_epochs=30)\n",
    "\n",
    "torch.save(trainer._classifier.model.state_dict(), 'certified_training_model.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7855a8c-0ab0-4ee6-a7b9-380d6c2360cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    test_preds = model(torch.from_numpy(x_test).float().to(device))\n",
    "\n",
    "test_preds = np.argmax(test_preds.cpu().detach().numpy(), axis=1)\n",
    "print('Test acc: ', np.mean(test_preds == y_test) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c3e186",
   "metadata": {},
   "outputs": [],
   "source": [
    "certification_loop(x=np.copy(x_test),\n",
    "                   y=y_test,\n",
    "                   preds=test_preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
